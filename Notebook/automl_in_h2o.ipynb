{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "# Gradient Boosted Trees and AutoML\n",
    "\n",
    "Last updated: Jul 13th 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "This Gradient Notebook is part of the project *Gradient Boosted Trees and AutoML* at https://github.com/gradient-ai/Classical-ML-Example .\n",
    "\n",
    "Business and other problems not amenable to deep learning are often best solved by using well-tuned Gradient-boosted decision trees. These methods are, like deep learning, capable of solving arbitrarily complex problems via nonlinear mappings, but can do so without requiring the large training sets and compute-intensive processing that deep learning sometimes can.\n",
    "\n",
    "This project shows that such methods are supported on Gradient by demonstrating training of **gradient-boosted decision trees** (GBT) using the well-known open source machine learning (ML) library H2O.\n",
    "\n",
    "We also show H2O's **automated machine learning** (AutoML) capability that can search the model hyperparameter tuning space. This can both save the user time required to so do manually, and produce better results by finding hyperparameter combinations that the user may miss. AutoML used in this way can surpass even expert human data scientists in some situations.\n",
    "\n",
    "H2O's AutoML includes within it another well-known GBT library, **XGBoost**.\n",
    "\n",
    "This project does not aim to show extensive model tuning, large datasets, or specific business problems, but to show the **end-to-end** combination of data preparation, model training, and deployment to production of the H2O model that is enabled within Gradient. We therefore show the commonly used [Census Income Dataset](https://archive.ics.uci.edu/ml/datasets/census+income) from the UCI ML repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "outputs": [],
   "source": [
    "# Copied from gbm_in_h2o.ipynb and modified\n",
    "# Try on income dataset since know expected performance gini ~ 0.86\n",
    "# http://docs.h2o.ai/h2o/latest-stable/h2o-docs/automl.html (also has example)\n",
    "#\n",
    "# Jun 14th 2019\n",
    "# Jun 17th 2021: Run on Gradient\n",
    "# Jun 21st 2021: Add save model as MOJO\n",
    "# Jul 13th 2021: Polish text to make shareable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "## Setup\n",
    "This Notebook runs on the Gradient container `tensorflow/tensorflow:2.4.1-gpu-jupyter`, and requires the installation of H2O, and hence Java."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "source_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: h2o==3.32.1.3 in /usr/local/lib/python3.6/dist-packages (3.32.1.3)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from h2o==3.32.1.3) (0.18.2)\n",
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from h2o==3.32.1.3) (0.8.9)\n",
      "Requirement already satisfied: colorama>=0.3.8 in /usr/local/lib/python3.6/dist-packages (from h2o==3.32.1.3) (0.4.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from h2o==3.32.1.3) (2.25.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/lib/python3/dist-packages (from requests->h2o==3.32.1.3) (2.6)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->h2o==3.32.1.3) (1.26.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->h2o==3.32.1.3) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->h2o==3.32.1.3) (4.0.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.1.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install H2O\n",
    "!pip install h2o==3.32.1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "source_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: install-jdk in /usr/local/lib/python3.6/dist-packages (0.3.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.1.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install Java using https://pypi.org/project/install-jdk/\n",
    "!pip install install-jdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "source_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-e806264e0417>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# but it is OK to proceed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjdk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mjdk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'11'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjre\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jdk/__init__.py\u001b[0m in \u001b[0;36minstall\u001b[0;34m(version, operating_system, arch, impl, jre, path)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0mjdk_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0mjdk_ext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_normalized_compressed_file_ext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjdk_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0mjdk_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_decompress_archive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjdk_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjdk_ext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mjdk_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jdk/__init__.py\u001b[0m in \u001b[0;36m_decompress_archive\u001b[0;34m(repo_root, file_ending, destination_folder)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjdk_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0mjdk_directory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extract_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjdk_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_ending\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestination_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0mjdk_bin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjdk_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"bin\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0m_unpack_jars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjdk_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjdk_bin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jdk/__init__.py\u001b[0m in \u001b[0;36m_extract_files\u001b[0;34m(file, file_ending, destination_folder)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mend_listing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestination_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0mjdk_directory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_listing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdifference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_listing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestination_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjdk_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# This may show an error if jdk is already installed from a previous run of the notebook,\n",
    "# but it is OK to proceed\n",
    "\n",
    "import jdk\n",
    "\n",
    "jdk.install('11', jre=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "Add the Java to the path so that H2O can see it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "source_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args='echo $PATH', returncode=0, stdout='/root/.jre/jdk-11.0.11+9-jre/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\\n')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "os.environ['PATH'] = \"/root/.jre/jdk-11.0.11+9-jre/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\"\n",
    "subprocess.run('echo $PATH', shell=True, check=True, stdout=subprocess.PIPE, universal_newlines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "H2O runs as a server, so we start this up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321 ..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: openjdk version \"11.0.11\" 2021-04-20; OpenJDK Runtime Environment AdoptOpenJDK-11.0.11+9 (build 11.0.11+9); OpenJDK 64-Bit Server VM AdoptOpenJDK-11.0.11+9 (build 11.0.11+9, mixed mode)\n",
      "  Starting server from /usr/local/lib/python3.6/dist-packages/h2o/backend/bin/h2o.jar\n",
      "  Ice root: /tmp/tmpbpb46tm5\n",
      "  JVM stdout: /tmp/tmpbpb46tm5/h2o_unknownUser_started_from_python.out\n",
      "  JVM stderr: /tmp/tmpbpb46tm5/h2o_unknownUser_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>02 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Etc/GMT</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.32.1.3</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>1 month and 24 days </td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_unknownUser_fku9br</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>6.750 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O_API_Extensions:</td>\n",
       "<td>Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.6.9 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ------------------------------------------------------------------\n",
       "H2O_cluster_uptime:         02 secs\n",
       "H2O_cluster_timezone:       Etc/GMT\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.32.1.3\n",
       "H2O_cluster_version_age:    1 month and 24 days\n",
       "H2O_cluster_name:           H2O_from_python_unknownUser_fku9br\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    6.750 Gb\n",
       "H2O_cluster_total_cores:    8\n",
       "H2O_cluster_allowed_cores:  8\n",
       "H2O_cluster_status:         accepting new members, healthy\n",
       "H2O_connection_url:         http://127.0.0.1:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "H2O_API_Extensions:         Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4\n",
       "Python_version:             3.6.9 final\n",
       "--------------------------  ------------------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "h2o.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "## Prepare data\n",
    "We load the slightly modified version of the income dataset supplied with the repo. This saves some data cleaning lines not relevant to this project such as removing the final empty line.\n",
    "\n",
    "The original data is at the [UCI ML Repository](https://archive.ics.uci.edu/ml/datasets/census+income) .\n",
    "\n",
    "H2O provides an `import_file` method that enables convenient import of a CSV file to a dataframe. This process is fine here because the data are small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "df = h2o.import_file(path = \"income.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "The data can be viewed. It consists of 14 columns of demographic information of mixed data type, and a binary ground-truth column `yearly-income`.\n",
    "\n",
    "Our task is to build a binary supervised ML classification model to predict whether a person's income is low (`<=50K`) or high (`>50K`).\n",
    "\n",
    "This has obvious potential business applications, such as deciding who to market cheap or expensive products to, but we will not explore those here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  age</th><th>workclass       </th><th style=\"text-align: right;\">  fnlwgt</th><th>education  </th><th style=\"text-align: right;\">  education-num</th><th>marital-status       </th><th>occupation       </th><th>relationship  </th><th>race  </th><th>sex   </th><th style=\"text-align: right;\">  capital-gain</th><th style=\"text-align: right;\">  capital-loss</th><th style=\"text-align: right;\">  hours-per-week</th><th>native-country  </th><th>yearly-income  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">   39</td><td>State-gov       </td><td style=\"text-align: right;\">   77516</td><td>Bachelors  </td><td style=\"text-align: right;\">             13</td><td>Never-married        </td><td>Adm-clerical     </td><td>Not-in-family </td><td>White </td><td>Male  </td><td style=\"text-align: right;\">          2174</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">              40</td><td>United-States   </td><td>&lt;=50K          </td></tr>\n",
       "<tr><td style=\"text-align: right;\">   50</td><td>Self-emp-not-inc</td><td style=\"text-align: right;\">   83311</td><td>Bachelors  </td><td style=\"text-align: right;\">             13</td><td>Married-civ-spouse   </td><td>Exec-managerial  </td><td>Husband       </td><td>White </td><td>Male  </td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">              13</td><td>United-States   </td><td>&lt;=50K          </td></tr>\n",
       "<tr><td style=\"text-align: right;\">   38</td><td>Private         </td><td style=\"text-align: right;\">  215646</td><td>HS-grad    </td><td style=\"text-align: right;\">              9</td><td>Divorced             </td><td>Handlers-cleaners</td><td>Not-in-family </td><td>White </td><td>Male  </td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">              40</td><td>United-States   </td><td>&lt;=50K          </td></tr>\n",
       "<tr><td style=\"text-align: right;\">   53</td><td>Private         </td><td style=\"text-align: right;\">  234721</td><td>11th       </td><td style=\"text-align: right;\">              7</td><td>Married-civ-spouse   </td><td>Handlers-cleaners</td><td>Husband       </td><td>Black </td><td>Male  </td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">              40</td><td>United-States   </td><td>&lt;=50K          </td></tr>\n",
       "<tr><td style=\"text-align: right;\">   28</td><td>Private         </td><td style=\"text-align: right;\">  338409</td><td>Bachelors  </td><td style=\"text-align: right;\">             13</td><td>Married-civ-spouse   </td><td>Prof-specialty   </td><td>Wife          </td><td>Black </td><td>Female</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">              40</td><td>Cuba            </td><td>&lt;=50K          </td></tr>\n",
       "<tr><td style=\"text-align: right;\">   37</td><td>Private         </td><td style=\"text-align: right;\">  284582</td><td>Masters    </td><td style=\"text-align: right;\">             14</td><td>Married-civ-spouse   </td><td>Exec-managerial  </td><td>Wife          </td><td>White </td><td>Female</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">              40</td><td>United-States   </td><td>&lt;=50K          </td></tr>\n",
       "<tr><td style=\"text-align: right;\">   49</td><td>Private         </td><td style=\"text-align: right;\">  160187</td><td>9th        </td><td style=\"text-align: right;\">              5</td><td>Married-spouse-absent</td><td>Other-service    </td><td>Not-in-family </td><td>Black </td><td>Female</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">              16</td><td>Jamaica         </td><td>&lt;=50K          </td></tr>\n",
       "<tr><td style=\"text-align: right;\">   52</td><td>Self-emp-not-inc</td><td style=\"text-align: right;\">  209642</td><td>HS-grad    </td><td style=\"text-align: right;\">              9</td><td>Married-civ-spouse   </td><td>Exec-managerial  </td><td>Husband       </td><td>White </td><td>Male  </td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">              45</td><td>United-States   </td><td>&gt;50K           </td></tr>\n",
       "<tr><td style=\"text-align: right;\">   31</td><td>Private         </td><td style=\"text-align: right;\">   45781</td><td>Masters    </td><td style=\"text-align: right;\">             14</td><td>Never-married        </td><td>Prof-specialty   </td><td>Not-in-family </td><td>White </td><td>Female</td><td style=\"text-align: right;\">         14084</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">              50</td><td>United-States   </td><td>&gt;50K           </td></tr>\n",
       "<tr><td style=\"text-align: right;\">   42</td><td>Private         </td><td style=\"text-align: right;\">  159449</td><td>Bachelors  </td><td style=\"text-align: right;\">             13</td><td>Married-civ-spouse   </td><td>Exec-managerial  </td><td>Husband       </td><td>White </td><td>Male  </td><td style=\"text-align: right;\">          5178</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">              40</td><td>United-States   </td><td>&gt;50K           </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "We can also summarize the dataframe with various statistics particularly useful for the exploratory data science that we are performing, using H2O's `summary()` method. Information includes min/max/spread, but also data type, number of zeros, and number of missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "source_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>       </th><th>age               </th><th>workclass       </th><th>fnlwgt            </th><th>education  </th><th>education-num     </th><th>marital-status       </th><th>occupation       </th><th>relationship  </th><th>race  </th><th>sex   </th><th>capital-gain      </th><th>capital-loss      </th><th>hours-per-week    </th><th>native-country  </th><th>yearly-income  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>type   </td><td>int               </td><td>enum            </td><td>int               </td><td>enum       </td><td>int               </td><td>enum                 </td><td>enum             </td><td>enum          </td><td>enum  </td><td>enum  </td><td>int               </td><td>int               </td><td>int               </td><td>enum            </td><td>enum           </td></tr>\n",
       "<tr><td>mins   </td><td>17.0              </td><td>                </td><td>12285.0           </td><td>           </td><td>1.0               </td><td>                     </td><td>                 </td><td>              </td><td>      </td><td>      </td><td>0.0               </td><td>0.0               </td><td>1.0               </td><td>                </td><td>               </td></tr>\n",
       "<tr><td>mean   </td><td>38.58164675532078 </td><td>                </td><td>189778.36651208502</td><td>           </td><td>10.0806793403151  </td><td>                     </td><td>                 </td><td>              </td><td>      </td><td>      </td><td>1077.6488437087312</td><td>87.303829734959   </td><td>40.437455852092995</td><td>                </td><td>               </td></tr>\n",
       "<tr><td>maxs   </td><td>90.0              </td><td>                </td><td>1484705.0         </td><td>           </td><td>16.0              </td><td>                     </td><td>                 </td><td>              </td><td>      </td><td>      </td><td>99999.0           </td><td>4356.0            </td><td>99.0              </td><td>                </td><td>               </td></tr>\n",
       "<tr><td>sigma  </td><td>13.640432553581341</td><td>                </td><td>105549.97769702224</td><td>           </td><td>2.5727203320673877</td><td>                     </td><td>                 </td><td>              </td><td>      </td><td>      </td><td>7385.29208484034  </td><td>402.96021864899967</td><td>12.347428681731843</td><td>                </td><td>               </td></tr>\n",
       "<tr><td>zeros  </td><td>0                 </td><td>                </td><td>0                 </td><td>           </td><td>0                 </td><td>                     </td><td>                 </td><td>              </td><td>      </td><td>      </td><td>29849             </td><td>31042             </td><td>0                 </td><td>                </td><td>               </td></tr>\n",
       "<tr><td>missing</td><td>0                 </td><td>0               </td><td>0                 </td><td>0          </td><td>0                 </td><td>0                    </td><td>0                </td><td>0             </td><td>0     </td><td>0     </td><td>0                 </td><td>0                 </td><td>0                 </td><td>0               </td><td>0              </td></tr>\n",
       "<tr><td>0      </td><td>39.0              </td><td>State-gov       </td><td>77516.0           </td><td>Bachelors  </td><td>13.0              </td><td>Never-married        </td><td>Adm-clerical     </td><td>Not-in-family </td><td>White </td><td>Male  </td><td>2174.0            </td><td>0.0               </td><td>40.0              </td><td>United-States   </td><td>&lt;=50K          </td></tr>\n",
       "<tr><td>1      </td><td>50.0              </td><td>Self-emp-not-inc</td><td>83311.0           </td><td>Bachelors  </td><td>13.0              </td><td>Married-civ-spouse   </td><td>Exec-managerial  </td><td>Husband       </td><td>White </td><td>Male  </td><td>0.0               </td><td>0.0               </td><td>13.0              </td><td>United-States   </td><td>&lt;=50K          </td></tr>\n",
       "<tr><td>2      </td><td>38.0              </td><td>Private         </td><td>215646.0          </td><td>HS-grad    </td><td>9.0               </td><td>Divorced             </td><td>Handlers-cleaners</td><td>Not-in-family </td><td>White </td><td>Male  </td><td>0.0               </td><td>0.0               </td><td>40.0              </td><td>United-States   </td><td>&lt;=50K          </td></tr>\n",
       "<tr><td>3      </td><td>53.0              </td><td>Private         </td><td>234721.0          </td><td>11th       </td><td>7.0               </td><td>Married-civ-spouse   </td><td>Handlers-cleaners</td><td>Husband       </td><td>Black </td><td>Male  </td><td>0.0               </td><td>0.0               </td><td>40.0              </td><td>United-States   </td><td>&lt;=50K          </td></tr>\n",
       "<tr><td>4      </td><td>28.0              </td><td>Private         </td><td>338409.0          </td><td>Bachelors  </td><td>13.0              </td><td>Married-civ-spouse   </td><td>Prof-specialty   </td><td>Wife          </td><td>Black </td><td>Female</td><td>0.0               </td><td>0.0               </td><td>40.0              </td><td>Cuba            </td><td>&lt;=50K          </td></tr>\n",
       "<tr><td>5      </td><td>37.0              </td><td>Private         </td><td>284582.0          </td><td>Masters    </td><td>14.0              </td><td>Married-civ-spouse   </td><td>Exec-managerial  </td><td>Wife          </td><td>White </td><td>Female</td><td>0.0               </td><td>0.0               </td><td>40.0              </td><td>United-States   </td><td>&lt;=50K          </td></tr>\n",
       "<tr><td>6      </td><td>49.0              </td><td>Private         </td><td>160187.0          </td><td>9th        </td><td>5.0               </td><td>Married-spouse-absent</td><td>Other-service    </td><td>Not-in-family </td><td>Black </td><td>Female</td><td>0.0               </td><td>0.0               </td><td>16.0              </td><td>Jamaica         </td><td>&lt;=50K          </td></tr>\n",
       "<tr><td>7      </td><td>52.0              </td><td>Self-emp-not-inc</td><td>209642.0          </td><td>HS-grad    </td><td>9.0               </td><td>Married-civ-spouse   </td><td>Exec-managerial  </td><td>Husband       </td><td>White </td><td>Male  </td><td>0.0               </td><td>0.0               </td><td>45.0              </td><td>United-States   </td><td>&gt;50K           </td></tr>\n",
       "<tr><td>8      </td><td>31.0              </td><td>Private         </td><td>45781.0           </td><td>Masters    </td><td>14.0              </td><td>Never-married        </td><td>Prof-specialty   </td><td>Not-in-family </td><td>White </td><td>Female</td><td>14084.0           </td><td>0.0               </td><td>50.0              </td><td>United-States   </td><td>&gt;50K           </td></tr>\n",
       "<tr><td>9      </td><td>42.0              </td><td>Private         </td><td>159449.0          </td><td>Bachelors  </td><td>13.0              </td><td>Married-civ-spouse   </td><td>Exec-managerial  </td><td>Husband       </td><td>White </td><td>Male  </td><td>5178.0            </td><td>0.0               </td><td>40.0              </td><td>United-States   </td><td>&gt;50K           </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "We separate the data feature columns (1-14) from the label in column 15 (yearly-income)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country']\n"
     ]
    }
   ],
   "source": [
    "# Feature columns and label\n",
    "y = \"yearly-income\"\n",
    "x = df.columns\n",
    "del x[14]\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "And split the data into a training, validation, and testing set.\n",
    "\n",
    "In H2O, the datasets are put into their *hex* format, which improves performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "outputs": [],
   "source": [
    "# Split\n",
    "train, valid, test = df.split_frame(\n",
    "    ratios = [0.6,0.2],\n",
    "    seed = 123456,\n",
    "    destination_frames=['train.hex','valid.hex','test.hex']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "## Train the model using AutoML\n",
    "\n",
    "Model training can then be performed using AutoML. Here we set the maximum number of models to search to be 20. The training takes a few minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML progress: |████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "# Run AutoML\n",
    "aml = H2OAutoML(max_models=20, seed=1)\n",
    "aml.train(x=x, y=y, training_frame=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "We see from the searched models that a variety of configurations have been tried, including:\n",
    "\n",
    " - Regular GBT (aka. GBM, gradient boosting machine)\n",
    " - XGBoost model with grid of hyperparameter values\n",
    " - A deep learning model\n",
    " - Random forest\n",
    " - Stacked ensembles of models (stacking = feed model output into next model input)\n",
    "\n",
    "For full details of the models searched in AutoML, see [H2O's AutoML documentation](https://docs.h2o.ai/h2o/latest-stable/h2o-docs/automl.html).\n",
    "\n",
    "We also see in the table various metrics for the model performance on the validation set, the leaderboard here being ordered by `auc`, which is the area under curve of model true versus false positive rate. Other [metrics](https://docs.h2o.ai/h2o/latest-stable/h2o-docs/performance-and-prediction.html?#classification) shown include logarithmic loss, area under precision-recall curve, and mean squared error.\n",
    "\n",
    "Gradient includes support for [tracking model metrics](https://docs.paperspace.com/gradient/data/metrics-overview), both in model experimentation and production.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>model_id                                           </th><th style=\"text-align: right;\">     auc</th><th style=\"text-align: right;\">  logloss</th><th style=\"text-align: right;\">   aucpr</th><th style=\"text-align: right;\">  mean_per_class_error</th><th style=\"text-align: right;\">    rmse</th><th style=\"text-align: right;\">      mse</th><th style=\"text-align: right;\">  training_time_ms</th><th style=\"text-align: right;\">  predict_time_per_row_ms</th><th>algo           </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>StackedEnsemble_AllModels_AutoML_20210713_220658   </td><td style=\"text-align: right;\">0.927879</td><td style=\"text-align: right;\"> 0.279676</td><td style=\"text-align: right;\">0.828378</td><td style=\"text-align: right;\">              0.17474 </td><td style=\"text-align: right;\">0.298163</td><td style=\"text-align: right;\">0.0889014</td><td style=\"text-align: right;\">              3856</td><td style=\"text-align: right;\">                 0.051449</td><td>StackedEnsemble</td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_AutoML_20210713_220658</td><td style=\"text-align: right;\">0.927704</td><td style=\"text-align: right;\"> 0.279957</td><td style=\"text-align: right;\">0.82827 </td><td style=\"text-align: right;\">              0.175113</td><td style=\"text-align: right;\">0.29824 </td><td style=\"text-align: right;\">0.0889473</td><td style=\"text-align: right;\">              2154</td><td style=\"text-align: right;\">                 0.018812</td><td>StackedEnsemble</td></tr>\n",
       "<tr><td>XGBoost_grid__1_AutoML_20210713_220658_model_4     </td><td style=\"text-align: right;\">0.926603</td><td style=\"text-align: right;\"> 0.281722</td><td style=\"text-align: right;\">0.825606</td><td style=\"text-align: right;\">              0.168536</td><td style=\"text-align: right;\">0.299547</td><td style=\"text-align: right;\">0.0897281</td><td style=\"text-align: right;\">               945</td><td style=\"text-align: right;\">                 0.002455</td><td>XGBoost        </td></tr>\n",
       "<tr><td>GBM_1_AutoML_20210713_220658                       </td><td style=\"text-align: right;\">0.925137</td><td style=\"text-align: right;\"> 0.285528</td><td style=\"text-align: right;\">0.823712</td><td style=\"text-align: right;\">              0.172024</td><td style=\"text-align: right;\">0.30061 </td><td style=\"text-align: right;\">0.0903661</td><td style=\"text-align: right;\">              1662</td><td style=\"text-align: right;\">                 0.019172</td><td>GBM            </td></tr>\n",
       "<tr><td>GBM_2_AutoML_20210713_220658                       </td><td style=\"text-align: right;\">0.924914</td><td style=\"text-align: right;\"> 0.286024</td><td style=\"text-align: right;\">0.823076</td><td style=\"text-align: right;\">              0.173164</td><td style=\"text-align: right;\">0.300807</td><td style=\"text-align: right;\">0.0904848</td><td style=\"text-align: right;\">              1579</td><td style=\"text-align: right;\">                 0.01554 </td><td>GBM            </td></tr>\n",
       "<tr><td>XGBoost_3_AutoML_20210713_220658                   </td><td style=\"text-align: right;\">0.924494</td><td style=\"text-align: right;\"> 0.28605 </td><td style=\"text-align: right;\">0.820167</td><td style=\"text-align: right;\">              0.17028 </td><td style=\"text-align: right;\">0.301813</td><td style=\"text-align: right;\">0.0910908</td><td style=\"text-align: right;\">               903</td><td style=\"text-align: right;\">                 0.002192</td><td>XGBoost        </td></tr>\n",
       "<tr><td>GBM_3_AutoML_20210713_220658                       </td><td style=\"text-align: right;\">0.924139</td><td style=\"text-align: right;\"> 0.287323</td><td style=\"text-align: right;\">0.821868</td><td style=\"text-align: right;\">              0.173311</td><td style=\"text-align: right;\">0.301484</td><td style=\"text-align: right;\">0.0908926</td><td style=\"text-align: right;\">              1577</td><td style=\"text-align: right;\">                 0.013665</td><td>GBM            </td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20210713_220658_model_1         </td><td style=\"text-align: right;\">0.922166</td><td style=\"text-align: right;\"> 0.291503</td><td style=\"text-align: right;\">0.816782</td><td style=\"text-align: right;\">              0.179959</td><td style=\"text-align: right;\">0.303526</td><td style=\"text-align: right;\">0.092128 </td><td style=\"text-align: right;\">              1442</td><td style=\"text-align: right;\">                 0.014716</td><td>GBM            </td></tr>\n",
       "<tr><td>XGBoost_grid__1_AutoML_20210713_220658_model_3     </td><td style=\"text-align: right;\">0.921608</td><td style=\"text-align: right;\"> 0.291206</td><td style=\"text-align: right;\">0.814513</td><td style=\"text-align: right;\">              0.172251</td><td style=\"text-align: right;\">0.304343</td><td style=\"text-align: right;\">0.0926247</td><td style=\"text-align: right;\">               841</td><td style=\"text-align: right;\">                 0.00224 </td><td>XGBoost        </td></tr>\n",
       "<tr><td>GBM_4_AutoML_20210713_220658                       </td><td style=\"text-align: right;\">0.921552</td><td style=\"text-align: right;\"> 0.292358</td><td style=\"text-align: right;\">0.816714</td><td style=\"text-align: right;\">              0.167862</td><td style=\"text-align: right;\">0.304239</td><td style=\"text-align: right;\">0.0925616</td><td style=\"text-align: right;\">              1675</td><td style=\"text-align: right;\">                 0.012231</td><td>GBM            </td></tr>\n",
       "<tr><td>XGBoost_grid__1_AutoML_20210713_220658_model_1     </td><td style=\"text-align: right;\">0.920121</td><td style=\"text-align: right;\"> 0.293489</td><td style=\"text-align: right;\">0.811588</td><td style=\"text-align: right;\">              0.181049</td><td style=\"text-align: right;\">0.305814</td><td style=\"text-align: right;\">0.0935221</td><td style=\"text-align: right;\">              1023</td><td style=\"text-align: right;\">                 0.002229</td><td>XGBoost        </td></tr>\n",
       "<tr><td>GBM_5_AutoML_20210713_220658                       </td><td style=\"text-align: right;\">0.919813</td><td style=\"text-align: right;\"> 0.295047</td><td style=\"text-align: right;\">0.809746</td><td style=\"text-align: right;\">              0.176791</td><td style=\"text-align: right;\">0.306613</td><td style=\"text-align: right;\">0.0940116</td><td style=\"text-align: right;\">              1916</td><td style=\"text-align: right;\">                 0.013914</td><td>GBM            </td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20210713_220658_model_2         </td><td style=\"text-align: right;\">0.919633</td><td style=\"text-align: right;\"> 0.296454</td><td style=\"text-align: right;\">0.808175</td><td style=\"text-align: right;\">              0.169346</td><td style=\"text-align: right;\">0.307024</td><td style=\"text-align: right;\">0.0942634</td><td style=\"text-align: right;\">              2451</td><td style=\"text-align: right;\">                 0.019449</td><td>GBM            </td></tr>\n",
       "<tr><td>XGBoost_1_AutoML_20210713_220658                   </td><td style=\"text-align: right;\">0.919177</td><td style=\"text-align: right;\"> 0.296835</td><td style=\"text-align: right;\">0.809929</td><td style=\"text-align: right;\">              0.176166</td><td style=\"text-align: right;\">0.307325</td><td style=\"text-align: right;\">0.0944486</td><td style=\"text-align: right;\">              1230</td><td style=\"text-align: right;\">                 0.002434</td><td>XGBoost        </td></tr>\n",
       "<tr><td>XGBoost_grid__1_AutoML_20210713_220658_model_2     </td><td style=\"text-align: right;\">0.914093</td><td style=\"text-align: right;\"> 0.30665 </td><td style=\"text-align: right;\">0.799354</td><td style=\"text-align: right;\">              0.17817 </td><td style=\"text-align: right;\">0.312989</td><td style=\"text-align: right;\">0.0979622</td><td style=\"text-align: right;\">              2129</td><td style=\"text-align: right;\">                 0.002624</td><td>XGBoost        </td></tr>\n",
       "<tr><td>XGBoost_2_AutoML_20210713_220658                   </td><td style=\"text-align: right;\">0.9129  </td><td style=\"text-align: right;\"> 0.309072</td><td style=\"text-align: right;\">0.796666</td><td style=\"text-align: right;\">              0.182337</td><td style=\"text-align: right;\">0.314178</td><td style=\"text-align: right;\">0.0987075</td><td style=\"text-align: right;\">              1885</td><td style=\"text-align: right;\">                 0.002627</td><td>XGBoost        </td></tr>\n",
       "<tr><td>DRF_1_AutoML_20210713_220658                       </td><td style=\"text-align: right;\">0.910646</td><td style=\"text-align: right;\"> 0.342976</td><td style=\"text-align: right;\">0.796839</td><td style=\"text-align: right;\">              0.191282</td><td style=\"text-align: right;\">0.312544</td><td style=\"text-align: right;\">0.0976838</td><td style=\"text-align: right;\">              2376</td><td style=\"text-align: right;\">                 0.013508</td><td>DRF            </td></tr>\n",
       "<tr><td>XRT_1_AutoML_20210713_220658                       </td><td style=\"text-align: right;\">0.910381</td><td style=\"text-align: right;\"> 0.311692</td><td style=\"text-align: right;\">0.797681</td><td style=\"text-align: right;\">              0.191194</td><td style=\"text-align: right;\">0.313144</td><td style=\"text-align: right;\">0.098059 </td><td style=\"text-align: right;\">              2055</td><td style=\"text-align: right;\">                 0.012278</td><td>DRF            </td></tr>\n",
       "<tr><td>DeepLearning_1_AutoML_20210713_220658              </td><td style=\"text-align: right;\">0.91013 </td><td style=\"text-align: right;\"> 0.314055</td><td style=\"text-align: right;\">0.777116</td><td style=\"text-align: right;\">              0.185208</td><td style=\"text-align: right;\">0.317136</td><td style=\"text-align: right;\">0.100575 </td><td style=\"text-align: right;\">              1497</td><td style=\"text-align: right;\">                 0.003293</td><td>DeepLearning   </td></tr>\n",
       "<tr><td>GLM_1_AutoML_20210713_220658                       </td><td style=\"text-align: right;\">0.906934</td><td style=\"text-align: right;\"> 0.318976</td><td style=\"text-align: right;\">0.770894</td><td style=\"text-align: right;\">              0.185024</td><td style=\"text-align: right;\">0.319614</td><td style=\"text-align: right;\">0.102153 </td><td style=\"text-align: right;\">              1953</td><td style=\"text-align: right;\">                 0.002036</td><td>GLM            </td></tr>\n",
       "<tr><td>DeepLearning_grid__1_AutoML_20210713_220658_model_1</td><td style=\"text-align: right;\">0.905678</td><td style=\"text-align: right;\"> 0.336515</td><td style=\"text-align: right;\">0.772937</td><td style=\"text-align: right;\">              0.17986 </td><td style=\"text-align: right;\">0.320292</td><td style=\"text-align: right;\">0.102587 </td><td style=\"text-align: right;\">             62420</td><td style=\"text-align: right;\">                 0.003951</td><td>DeepLearning   </td></tr>\n",
       "<tr><td>DeepLearning_grid__2_AutoML_20210713_220658_model_1</td><td style=\"text-align: right;\">0.901855</td><td style=\"text-align: right;\"> 0.338676</td><td style=\"text-align: right;\">0.755727</td><td style=\"text-align: right;\">              0.192603</td><td style=\"text-align: right;\">0.325052</td><td style=\"text-align: right;\">0.105659 </td><td style=\"text-align: right;\">             97594</td><td style=\"text-align: right;\">                 0.004829</td><td>DeepLearning   </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb = h2o.automl.get_leaderboard(aml, extra_columns = 'ALL')\n",
    "lb.head(rows=lb.nrows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "The best model is the stacked ensemble, and we can see its properties in more detail. These include further metrics on model performance, such as the F-score harmonic mean of precision and recall, and the confusion matrix between predicted and ground truth labels, showing true and false positives and negatives. The information is shown for the training data, and then for the (cross-validated) validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2OStackedEnsembleEstimator :  Stacked Ensemble\n",
      "Model Key:  StackedEnsemble_AllModels_AutoML_20210713_220658\n",
      "\n",
      "No model summary for this model\n",
      "\n",
      "ModelMetricsBinomialGLM: stackedensemble\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.07353773014710141\n",
      "RMSE: 0.27117841017879984\n",
      "LogLoss: 0.23472354840397225\n",
      "Null degrees of freedom: 10046\n",
      "Residual degrees of freedom: 10038\n",
      "Null deviance: 11134.613562297965\n",
      "Residual deviance: 4716.534981629419\n",
      "AIC: 4734.534981629419\n",
      "AUC: 0.9527179829248879\n",
      "AUCPR: 0.8818935027134936\n",
      "Gini: 0.9054359658497757\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.442733533010321: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b><=50K</b></td>\n",
       "<td><b>>50K</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td><=50K</td>\n",
       "<td>7150.0</td>\n",
       "<td>459.0</td>\n",
       "<td>0.0603</td>\n",
       "<td> (459.0/7609.0)</td></tr>\n",
       "<tr><td>>50K</td>\n",
       "<td>570.0</td>\n",
       "<td>1868.0</td>\n",
       "<td>0.2338</td>\n",
       "<td> (570.0/2438.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>7720.0</td>\n",
       "<td>2327.0</td>\n",
       "<td>0.1024</td>\n",
       "<td> (1029.0/10047.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       <=50K    >50K    Error    Rate\n",
       "-----  -------  ------  -------  ----------------\n",
       "<=50K  7150     459     0.0603   (459.0/7609.0)\n",
       ">50K   570      1868    0.2338   (570.0/2438.0)\n",
       "Total  7720     2327    0.1024   (1029.0/10047.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.4427335</td>\n",
       "<td>0.7840504</td>\n",
       "<td>180.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.2235808</td>\n",
       "<td>0.8474576</td>\n",
       "<td>267.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.5803231</td>\n",
       "<td>0.8179173</td>\n",
       "<td>134.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4885390</td>\n",
       "<td>0.8979795</td>\n",
       "<td>164.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9985563</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0093222</td>\n",
       "<td>1.0</td>\n",
       "<td>385.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9985563</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.4427335</td>\n",
       "<td>0.7173048</td>\n",
       "<td>180.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.3107194</td>\n",
       "<td>0.8761280</td>\n",
       "<td>232.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.2737748</td>\n",
       "<td>0.8788908</td>\n",
       "<td>247.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.9985563</td>\n",
       "<td>7609.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.9985563</td>\n",
       "<td>2339.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0005245</td>\n",
       "<td>7609.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.0093222</td>\n",
       "<td>2438.0</td>\n",
       "<td>385.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.9985563</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.9985563</td>\n",
       "<td>0.9593929</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0005245</td>\n",
       "<td>1.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.0093222</td>\n",
       "<td>1.0</td>\n",
       "<td>385.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.442734     0.78405   180\n",
       "max f2                       0.223581     0.847458  267\n",
       "max f0point5                 0.580323     0.817917  134\n",
       "max accuracy                 0.488539     0.897979  164\n",
       "max precision                0.998556     1         0\n",
       "max recall                   0.0093222    1         385\n",
       "max specificity              0.998556     1         0\n",
       "max absolute_mcc             0.442734     0.717305  180\n",
       "max min_per_class_accuracy   0.310719     0.876128  232\n",
       "max mean_per_class_accuracy  0.273775     0.878891  247\n",
       "max tns                      0.998556     7609      0\n",
       "max fns                      0.998556     2339      0\n",
       "max fps                      0.000524497  7609      399\n",
       "max tps                      0.0093222    2438      385\n",
       "max tnr                      0.998556     1         0\n",
       "max fnr                      0.998556     0.959393  0\n",
       "max fpr                      0.000524497  1         399\n",
       "max tpr                      0.0093222    1         385"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate: 24.27 %, avg score: 24.29 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td>\n",
       "<td><b>kolmogorov_smirnov</b></td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.0100528</td>\n",
       "<td>0.9979695</td>\n",
       "<td>4.1210008</td>\n",
       "<td>4.1210008</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9985509</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9985509</td>\n",
       "<td>0.0414274</td>\n",
       "<td>0.0414274</td>\n",
       "<td>312.1000820</td>\n",
       "<td>312.1000820</td>\n",
       "<td>0.0414274</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0200060</td>\n",
       "<td>0.9961053</td>\n",
       "<td>4.1210008</td>\n",
       "<td>4.1210008</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9971042</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9978312</td>\n",
       "<td>0.0410172</td>\n",
       "<td>0.0824446</td>\n",
       "<td>312.1000820</td>\n",
       "<td>312.1000820</td>\n",
       "<td>0.0824446</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0300587</td>\n",
       "<td>0.9939651</td>\n",
       "<td>4.1210008</td>\n",
       "<td>4.1210008</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9952166</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9969568</td>\n",
       "<td>0.0414274</td>\n",
       "<td>0.1238720</td>\n",
       "<td>312.1000820</td>\n",
       "<td>312.1000820</td>\n",
       "<td>0.1238720</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0400119</td>\n",
       "<td>0.9887968</td>\n",
       "<td>4.1210008</td>\n",
       "<td>4.1210008</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9918443</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9956850</td>\n",
       "<td>0.0410172</td>\n",
       "<td>0.1648893</td>\n",
       "<td>312.1000820</td>\n",
       "<td>312.1000820</td>\n",
       "<td>0.1648893</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.0500647</td>\n",
       "<td>0.9749837</td>\n",
       "<td>4.1210008</td>\n",
       "<td>4.1210008</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9821951</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9929763</td>\n",
       "<td>0.0414274</td>\n",
       "<td>0.2063167</td>\n",
       "<td>312.1000820</td>\n",
       "<td>312.1000820</td>\n",
       "<td>0.2063167</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1000299</td>\n",
       "<td>0.7909157</td>\n",
       "<td>3.9157717</td>\n",
       "<td>4.0184884</td>\n",
       "<td>0.9501992</td>\n",
       "<td>0.8883450</td>\n",
       "<td>0.9751244</td>\n",
       "<td>0.9407127</td>\n",
       "<td>0.1956522</td>\n",
       "<td>0.4019688</td>\n",
       "<td>291.5771696</td>\n",
       "<td>301.8488362</td>\n",
       "<td>0.3986832</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.1499950</td>\n",
       "<td>0.6568419</td>\n",
       "<td>3.1605285</td>\n",
       "<td>3.7326915</td>\n",
       "<td>0.7669323</td>\n",
       "<td>0.7237687</td>\n",
       "<td>0.9057731</td>\n",
       "<td>0.8684461</td>\n",
       "<td>0.1579163</td>\n",
       "<td>0.5598852</td>\n",
       "<td>216.0528518</td>\n",
       "<td>273.2691519</td>\n",
       "<td>0.5412230</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2000597</td>\n",
       "<td>0.5173999</td>\n",
       "<td>2.7200244</td>\n",
       "<td>3.4792728</td>\n",
       "<td>0.6600398</td>\n",
       "<td>0.5875094</td>\n",
       "<td>0.8442786</td>\n",
       "<td>0.7981420</td>\n",
       "<td>0.1361772</td>\n",
       "<td>0.6960623</td>\n",
       "<td>172.0024398</td>\n",
       "<td>247.9272832</td>\n",
       "<td>0.6549268</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.2999900</td>\n",
       "<td>0.3204674</td>\n",
       "<td>1.7075063</td>\n",
       "<td>2.8890759</td>\n",
       "<td>0.4143426</td>\n",
       "<td>0.4090260</td>\n",
       "<td>0.7010617</td>\n",
       "<td>0.6685227</td>\n",
       "<td>0.1706317</td>\n",
       "<td>0.8666940</td>\n",
       "<td>70.7506316</td>\n",
       "<td>188.9075890</td>\n",
       "<td>0.7482816</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.4000199</td>\n",
       "<td>0.1599700</td>\n",
       "<td>0.8734061</td>\n",
       "<td>2.3850331</td>\n",
       "<td>0.2119403</td>\n",
       "<td>0.2353812</td>\n",
       "<td>0.5787509</td>\n",
       "<td>0.5602104</td>\n",
       "<td>0.0873667</td>\n",
       "<td>0.9540607</td>\n",
       "<td>-12.6593856</td>\n",
       "<td>138.5033070</td>\n",
       "<td>0.7315610</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5000498</td>\n",
       "<td>0.0679070</td>\n",
       "<td>0.3034369</td>\n",
       "<td>1.9686310</td>\n",
       "<td>0.0736318</td>\n",
       "<td>0.1104197</td>\n",
       "<td>0.4777070</td>\n",
       "<td>0.4702344</td>\n",
       "<td>0.0303527</td>\n",
       "<td>0.9844135</td>\n",
       "<td>-69.6563124</td>\n",
       "<td>96.8630965</td>\n",
       "<td>0.6395587</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.5999801</td>\n",
       "<td>0.0290946</td>\n",
       "<td>0.1108237</td>\n",
       "<td>1.6592019</td>\n",
       "<td>0.0268924</td>\n",
       "<td>0.0451253</td>\n",
       "<td>0.4026211</td>\n",
       "<td>0.3994299</td>\n",
       "<td>0.0110747</td>\n",
       "<td>0.9954881</td>\n",
       "<td>-88.9176273</td>\n",
       "<td>65.9201890</td>\n",
       "<td>0.5222327</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.7000100</td>\n",
       "<td>0.0129978</td>\n",
       "<td>0.0328040</td>\n",
       "<td>1.4267933</td>\n",
       "<td>0.0079602</td>\n",
       "<td>0.0199844</td>\n",
       "<td>0.3462249</td>\n",
       "<td>0.3452080</td>\n",
       "<td>0.0032814</td>\n",
       "<td>0.9987695</td>\n",
       "<td>-96.7196013</td>\n",
       "<td>42.6793260</td>\n",
       "<td>0.3944851</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.7999403</td>\n",
       "<td>0.0053600</td>\n",
       "<td>0.0123137</td>\n",
       "<td>1.2500933</td>\n",
       "<td>0.0029880</td>\n",
       "<td>0.0087052</td>\n",
       "<td>0.3033470</td>\n",
       "<td>0.3031713</td>\n",
       "<td>0.0012305</td>\n",
       "<td>1.0</td>\n",
       "<td>-98.7686253</td>\n",
       "<td>25.0093318</td>\n",
       "<td>0.2641609</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.8999701</td>\n",
       "<td>0.0015750</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1111480</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0032477</td>\n",
       "<td>0.2696306</td>\n",
       "<td>0.2698354</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.1147976</td>\n",
       "<td>0.1320804</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000617</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0007984</td>\n",
       "<td>0.2426595</td>\n",
       "<td>0.2429236</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  ---------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
       "1        0.0100528                   0.99797            4.121      4.121              1                0.998551     1                           0.998551            0.0414274       0.0414274                  312.1     312.1              0.0414274\n",
       "2        0.020006                    0.996105           4.121      4.121              1                0.997104     1                           0.997831            0.0410172       0.0824446                  312.1     312.1              0.0824446\n",
       "3        0.0300587                   0.993965           4.121      4.121              1                0.995217     1                           0.996957            0.0414274       0.123872                   312.1     312.1              0.123872\n",
       "4        0.0400119                   0.988797           4.121      4.121              1                0.991844     1                           0.995685            0.0410172       0.164889                   312.1     312.1              0.164889\n",
       "5        0.0500647                   0.974984           4.121      4.121              1                0.982195     1                           0.992976            0.0414274       0.206317                   312.1     312.1              0.206317\n",
       "6        0.10003                     0.790916           3.91577    4.01849            0.950199         0.888345     0.975124                    0.940713            0.195652        0.401969                   291.577   301.849            0.398683\n",
       "7        0.149995                    0.656842           3.16053    3.73269            0.766932         0.723769     0.905773                    0.868446            0.157916        0.559885                   216.053   273.269            0.541223\n",
       "8        0.20006                     0.5174             2.72002    3.47927            0.66004          0.587509     0.844279                    0.798142            0.136177        0.696062                   172.002   247.927            0.654927\n",
       "9        0.29999                     0.320467           1.70751    2.88908            0.414343         0.409026     0.701062                    0.668523            0.170632        0.866694                   70.7506   188.908            0.748282\n",
       "10       0.40002                     0.15997            0.873406   2.38503            0.21194          0.235381     0.578751                    0.56021             0.0873667       0.954061                   -12.6594  138.503            0.731561\n",
       "11       0.50005                     0.067907           0.303437   1.96863            0.0736318        0.11042      0.477707                    0.470234            0.0303527       0.984413                   -69.6563  96.8631            0.639559\n",
       "12       0.59998                     0.0290946          0.110824   1.6592             0.0268924        0.0451253    0.402621                    0.39943             0.0110747       0.995488                   -88.9176  65.9202            0.522233\n",
       "13       0.70001                     0.0129978          0.032804   1.42679            0.0079602        0.0199844    0.346225                    0.345208            0.00328138      0.998769                   -96.7196  42.6793            0.394485\n",
       "14       0.79994                     0.00536004         0.0123137  1.25009            0.00298805       0.00870519   0.303347                    0.303171            0.00123052      1                          -98.7686  25.0093            0.264161\n",
       "15       0.89997                     0.00157505         0          1.11115            0                0.00324765   0.269631                    0.269835            0               1                          -100      11.1148            0.13208\n",
       "16       1                           6.16617e-05        0          1                  0                0.000798397  0.24266                     0.242924            0               1                          -100      0                  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomialGLM: stackedensemble\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 0.08890141184971788\n",
      "RMSE: 0.2981633979040987\n",
      "LogLoss: 0.2796763420174989\n",
      "Null degrees of freedom: 19679\n",
      "Residual degrees of freedom: 19672\n",
      "Null deviance: 21801.127810231956\n",
      "Residual deviance: 11008.060821808762\n",
      "AIC: 11024.060821808762\n",
      "AUC: 0.9278789682208023\n",
      "AUCPR: 0.8283780381517716\n",
      "Gini: 0.8557579364416046\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.39722559433554266: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b><=50K</b></td>\n",
       "<td><b>>50K</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td><=50K</td>\n",
       "<td>13486.0</td>\n",
       "<td>1423.0</td>\n",
       "<td>0.0954</td>\n",
       "<td> (1423.0/14909.0)</td></tr>\n",
       "<tr><td>>50K</td>\n",
       "<td>1212.0</td>\n",
       "<td>3559.0</td>\n",
       "<td>0.254</td>\n",
       "<td> (1212.0/4771.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>14698.0</td>\n",
       "<td>4982.0</td>\n",
       "<td>0.1339</td>\n",
       "<td> (2635.0/19680.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       <=50K    >50K    Error    Rate\n",
       "-----  -------  ------  -------  ----------------\n",
       "<=50K  13486    1423    0.0954   (1423.0/14909.0)\n",
       ">50K   1212     3559    0.254    (1212.0/4771.0)\n",
       "Total  14698    4982    0.1339   (2635.0/19680.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.3972256</td>\n",
       "<td>0.7298267</td>\n",
       "<td>198.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1442125</td>\n",
       "<td>0.8118176</td>\n",
       "<td>300.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.6025775</td>\n",
       "<td>0.7680444</td>\n",
       "<td>126.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4987898</td>\n",
       "<td>0.8720020</td>\n",
       "<td>161.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9985042</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0013010</td>\n",
       "<td>1.0</td>\n",
       "<td>397.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9985042</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.4063935</td>\n",
       "<td>0.6415411</td>\n",
       "<td>195.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.2804126</td>\n",
       "<td>0.8428003</td>\n",
       "<td>241.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.2526943</td>\n",
       "<td>0.8463403</td>\n",
       "<td>252.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.9985042</td>\n",
       "<td>14909.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.9985042</td>\n",
       "<td>4674.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0005065</td>\n",
       "<td>14909.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.0013010</td>\n",
       "<td>4771.0</td>\n",
       "<td>397.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.9985042</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.9985042</td>\n",
       "<td>0.9796688</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0005065</td>\n",
       "<td>1.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.0013010</td>\n",
       "<td>1.0</td>\n",
       "<td>397.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.397226     0.729827  198\n",
       "max f2                       0.144213     0.811818  300\n",
       "max f0point5                 0.602577     0.768044  126\n",
       "max accuracy                 0.49879      0.872002  161\n",
       "max precision                0.998504     1         0\n",
       "max recall                   0.00130095   1         397\n",
       "max specificity              0.998504     1         0\n",
       "max absolute_mcc             0.406394     0.641541  195\n",
       "max min_per_class_accuracy   0.280413     0.8428    241\n",
       "max mean_per_class_accuracy  0.252694     0.84634   252\n",
       "max tns                      0.998504     14909     0\n",
       "max fns                      0.998504     4674      0\n",
       "max fps                      0.000506486  14909     399\n",
       "max tps                      0.00130095   4771      397\n",
       "max tnr                      0.998504     1         0\n",
       "max fnr                      0.998504     0.979669  0\n",
       "max fpr                      0.000506486  1         399\n",
       "max tpr                      0.00130095   1         397"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate: 24.24 %, avg score: 24.25 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td>\n",
       "<td><b>kolmogorov_smirnov</b></td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.0100102</td>\n",
       "<td>0.9972772</td>\n",
       "<td>4.1249214</td>\n",
       "<td>4.1249214</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9980797</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9980797</td>\n",
       "<td>0.0412911</td>\n",
       "<td>0.0412911</td>\n",
       "<td>312.4921400</td>\n",
       "<td>312.4921400</td>\n",
       "<td>0.0412911</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0200203</td>\n",
       "<td>0.9951675</td>\n",
       "<td>4.1249214</td>\n",
       "<td>4.1249214</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9963080</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9971938</td>\n",
       "<td>0.0412911</td>\n",
       "<td>0.0825823</td>\n",
       "<td>312.4921400</td>\n",
       "<td>312.4921400</td>\n",
       "<td>0.0825823</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0300305</td>\n",
       "<td>0.9920232</td>\n",
       "<td>4.1039827</td>\n",
       "<td>4.1179418</td>\n",
       "<td>0.9949239</td>\n",
       "<td>0.9937343</td>\n",
       "<td>0.9983080</td>\n",
       "<td>0.9960406</td>\n",
       "<td>0.0410815</td>\n",
       "<td>0.1236638</td>\n",
       "<td>310.3982713</td>\n",
       "<td>311.7941838</td>\n",
       "<td>0.1235967</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0400407</td>\n",
       "<td>0.9849227</td>\n",
       "<td>4.0830440</td>\n",
       "<td>4.1092174</td>\n",
       "<td>0.9898477</td>\n",
       "<td>0.9886592</td>\n",
       "<td>0.9961929</td>\n",
       "<td>0.9941953</td>\n",
       "<td>0.0408719</td>\n",
       "<td>0.1645357</td>\n",
       "<td>308.3044026</td>\n",
       "<td>310.9217385</td>\n",
       "<td>0.1643345</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.05</td>\n",
       "<td>0.9710766</td>\n",
       "<td>4.1038759</td>\n",
       "<td>4.1081534</td>\n",
       "<td>0.9948980</td>\n",
       "<td>0.9790359</td>\n",
       "<td>0.9959350</td>\n",
       "<td>0.9911757</td>\n",
       "<td>0.0408719</td>\n",
       "<td>0.2054077</td>\n",
       "<td>310.3875883</td>\n",
       "<td>310.8153427</td>\n",
       "<td>0.2051394</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1</td>\n",
       "<td>0.7765685</td>\n",
       "<td>3.5548103</td>\n",
       "<td>3.8314819</td>\n",
       "<td>0.8617886</td>\n",
       "<td>0.8689297</td>\n",
       "<td>0.9288618</td>\n",
       "<td>0.9300527</td>\n",
       "<td>0.1777405</td>\n",
       "<td>0.3831482</td>\n",
       "<td>255.4810312</td>\n",
       "<td>283.1481870</td>\n",
       "<td>0.3737579</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.15</td>\n",
       "<td>0.6446937</td>\n",
       "<td>2.9637393</td>\n",
       "<td>3.5422343</td>\n",
       "<td>0.7184959</td>\n",
       "<td>0.7105667</td>\n",
       "<td>0.8587398</td>\n",
       "<td>0.8568907</td>\n",
       "<td>0.1481870</td>\n",
       "<td>0.5313351</td>\n",
       "<td>196.3739258</td>\n",
       "<td>254.2234332</td>\n",
       "<td>0.5033655</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2</td>\n",
       "<td>0.5081031</td>\n",
       "<td>2.3265563</td>\n",
       "<td>3.2383148</td>\n",
       "<td>0.5640244</td>\n",
       "<td>0.5761540</td>\n",
       "<td>0.7850610</td>\n",
       "<td>0.7867065</td>\n",
       "<td>0.1163278</td>\n",
       "<td>0.6476630</td>\n",
       "<td>132.6556278</td>\n",
       "<td>223.8314819</td>\n",
       "<td>0.5909187</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.3</td>\n",
       "<td>0.3188533</td>\n",
       "<td>1.6223014</td>\n",
       "<td>2.6996437</td>\n",
       "<td>0.3932927</td>\n",
       "<td>0.4064082</td>\n",
       "<td>0.6544715</td>\n",
       "<td>0.6599404</td>\n",
       "<td>0.1622301</td>\n",
       "<td>0.8098931</td>\n",
       "<td>62.2301404</td>\n",
       "<td>169.9643681</td>\n",
       "<td>0.6730630</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.4</td>\n",
       "<td>0.1677174</td>\n",
       "<td>1.0584783</td>\n",
       "<td>2.2893523</td>\n",
       "<td>0.2566057</td>\n",
       "<td>0.2381582</td>\n",
       "<td>0.5550051</td>\n",
       "<td>0.5544949</td>\n",
       "<td>0.1058478</td>\n",
       "<td>0.9157409</td>\n",
       "<td>5.8478306</td>\n",
       "<td>128.9352337</td>\n",
       "<td>0.6807822</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0752014</td>\n",
       "<td>0.5009432</td>\n",
       "<td>1.9316705</td>\n",
       "<td>0.1214431</td>\n",
       "<td>0.1175571</td>\n",
       "<td>0.4682927</td>\n",
       "<td>0.4671073</td>\n",
       "<td>0.0500943</td>\n",
       "<td>0.9658353</td>\n",
       "<td>-49.9056802</td>\n",
       "<td>93.1670509</td>\n",
       "<td>0.6149063</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.6</td>\n",
       "<td>0.0329291</td>\n",
       "<td>0.2012157</td>\n",
       "<td>1.6432614</td>\n",
       "<td>0.0487805</td>\n",
       "<td>0.0506598</td>\n",
       "<td>0.3983740</td>\n",
       "<td>0.3976994</td>\n",
       "<td>0.0201216</td>\n",
       "<td>0.9859568</td>\n",
       "<td>-79.8784322</td>\n",
       "<td>64.3261371</td>\n",
       "<td>0.5094661</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.7</td>\n",
       "<td>0.0153835</td>\n",
       "<td>0.0859359</td>\n",
       "<td>1.4207863</td>\n",
       "<td>0.0208333</td>\n",
       "<td>0.0229160</td>\n",
       "<td>0.3444396</td>\n",
       "<td>0.3441589</td>\n",
       "<td>0.0085936</td>\n",
       "<td>0.9945504</td>\n",
       "<td>-91.4064137</td>\n",
       "<td>42.0786298</td>\n",
       "<td>0.3888089</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.8</td>\n",
       "<td>0.0068278</td>\n",
       "<td>0.0419199</td>\n",
       "<td>1.2484280</td>\n",
       "<td>0.0101626</td>\n",
       "<td>0.0107593</td>\n",
       "<td>0.3026550</td>\n",
       "<td>0.3024840</td>\n",
       "<td>0.0041920</td>\n",
       "<td>0.9987424</td>\n",
       "<td>-95.8080067</td>\n",
       "<td>24.8428003</td>\n",
       "<td>0.2623416</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.9</td>\n",
       "<td>0.0019275</td>\n",
       "<td>0.0104800</td>\n",
       "<td>1.1108782</td>\n",
       "<td>0.0025407</td>\n",
       "<td>0.0040685</td>\n",
       "<td>0.2693089</td>\n",
       "<td>0.2693267</td>\n",
       "<td>0.0010480</td>\n",
       "<td>0.9997904</td>\n",
       "<td>-98.9520017</td>\n",
       "<td>11.0878223</td>\n",
       "<td>0.1317241</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0001106</td>\n",
       "<td>0.0020960</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0005081</td>\n",
       "<td>0.0009641</td>\n",
       "<td>0.2424289</td>\n",
       "<td>0.2424904</td>\n",
       "<td>0.0002096</td>\n",
       "<td>1.0</td>\n",
       "<td>-99.7904003</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  ---------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
       "1        0.0100102                   0.997277           4.12492    4.12492            1                0.99808      1                           0.99808             0.0412911       0.0412911                  312.492   312.492            0.0412911\n",
       "2        0.0200203                   0.995167           4.12492    4.12492            1                0.996308     1                           0.997194            0.0412911       0.0825823                  312.492   312.492            0.0825823\n",
       "3        0.0300305                   0.992023           4.10398    4.11794            0.994924         0.993734     0.998308                    0.996041            0.0410815       0.123664                   310.398   311.794            0.123597\n",
       "4        0.0400407                   0.984923           4.08304    4.10922            0.989848         0.988659     0.996193                    0.994195            0.0408719       0.164536                   308.304   310.922            0.164335\n",
       "5        0.05                        0.971077           4.10388    4.10815            0.994898         0.979036     0.995935                    0.991176            0.0408719       0.205408                   310.388   310.815            0.205139\n",
       "6        0.1                         0.776568           3.55481    3.83148            0.861789         0.86893      0.928862                    0.930053            0.177741        0.383148                   255.481   283.148            0.373758\n",
       "7        0.15                        0.644694           2.96374    3.54223            0.718496         0.710567     0.85874                     0.856891            0.148187        0.531335                   196.374   254.223            0.503365\n",
       "8        0.2                         0.508103           2.32656    3.23831            0.564024         0.576154     0.785061                    0.786707            0.116328        0.647663                   132.656   223.831            0.590919\n",
       "9        0.3                         0.318853           1.6223     2.69964            0.393293         0.406408     0.654472                    0.65994             0.16223         0.809893                   62.2301   169.964            0.673063\n",
       "10       0.4                         0.167717           1.05848    2.28935            0.256606         0.238158     0.555005                    0.554495            0.105848        0.915741                   5.84783   128.935            0.680782\n",
       "11       0.5                         0.0752014          0.500943   1.93167            0.121443         0.117557     0.468293                    0.467107            0.0500943       0.965835                   -49.9057  93.1671            0.614906\n",
       "12       0.6                         0.0329291          0.201216   1.64326            0.0487805        0.0506598    0.398374                    0.397699            0.0201216       0.985957                   -79.8784  64.3261            0.509466\n",
       "13       0.7                         0.0153835          0.0859359  1.42079            0.0208333        0.022916     0.34444                     0.344159            0.00859359      0.99455                    -91.4064  42.0786            0.388809\n",
       "14       0.8                         0.00682778         0.0419199  1.24843            0.0101626        0.0107593    0.302655                    0.302484            0.00419199      0.998742                   -95.808   24.8428            0.262342\n",
       "15       0.9                         0.00192752         0.01048    1.11088            0.00254065       0.00406851   0.269309                    0.269327            0.001048        0.99979                    -98.952   11.0878            0.131724\n",
       "16       1                           0.000110564        0.002096   1                  0.00050813       0.000964148  0.242429                    0.24249             0.0002096       1                          -99.7904  0                  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aml.leader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "## Model performance on testing set\n",
    "The measure of a model's likely performance in production is its performance on unseen data. Therefore it is common to hold out unseen a portion of the data as a testing set, and the model's performance measured against its ground truth.\n",
    "\n",
    "We can do this here by showing the model running predictions on the testing data (class probabilities), and analyzing its performance via the `model_performance()` method. This shows similar information to the `leader()` method above. We see that the model generalizes quite well to the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stackedensemble prediction progress: |████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "model = aml.leader\n",
    "predictions = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>predict  </th><th style=\"text-align: right;\">     &lt;=50K</th><th style=\"text-align: right;\">      &gt;50K</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>&lt;=50K    </td><td style=\"text-align: right;\">0.901984  </td><td style=\"text-align: right;\">0.0980157 </td></tr>\n",
       "<tr><td>&gt;50K     </td><td style=\"text-align: right;\">0.558392  </td><td style=\"text-align: right;\">0.441608  </td></tr>\n",
       "<tr><td>&gt;50K     </td><td style=\"text-align: right;\">0.00799326</td><td style=\"text-align: right;\">0.992007  </td></tr>\n",
       "<tr><td>&lt;=50K    </td><td style=\"text-align: right;\">0.99852   </td><td style=\"text-align: right;\">0.00147984</td></tr>\n",
       "<tr><td>&lt;=50K    </td><td style=\"text-align: right;\">0.985341  </td><td style=\"text-align: right;\">0.0146592 </td></tr>\n",
       "<tr><td>&lt;=50K    </td><td style=\"text-align: right;\">0.925742  </td><td style=\"text-align: right;\">0.0742579 </td></tr>\n",
       "<tr><td>&lt;=50K    </td><td style=\"text-align: right;\">0.675973  </td><td style=\"text-align: right;\">0.324027  </td></tr>\n",
       "<tr><td>&lt;=50K    </td><td style=\"text-align: right;\">0.998648  </td><td style=\"text-align: right;\">0.00135163</td></tr>\n",
       "<tr><td>&lt;=50K    </td><td style=\"text-align: right;\">0.713482  </td><td style=\"text-align: right;\">0.286518  </td></tr>\n",
       "<tr><td>&lt;=50K    </td><td style=\"text-align: right;\">0.995738  </td><td style=\"text-align: right;\">0.00426244</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "source_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsBinomialGLM: stackedensemble\n",
      "** Reported on test data. **\n",
      "\n",
      "MSE: 0.08459831945145556\n",
      "RMSE: 0.2908579025081759\n",
      "LogLoss: 0.26651807392826693\n",
      "Null degrees of freedom: 6384\n",
      "Residual degrees of freedom: 6376\n",
      "Null deviance: 6997.8448091152995\n",
      "Residual deviance: 3403.435804063969\n",
      "AIC: 3421.435804063969\n",
      "AUC: 0.9342385860762666\n",
      "AUCPR: 0.8380052497961226\n",
      "Gini: 0.8684771721525333\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.39413376060002026: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b><=50K</b></td>\n",
       "<td><b>>50K</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td><=50K</td>\n",
       "<td>4411.0</td>\n",
       "<td>459.0</td>\n",
       "<td>0.0943</td>\n",
       "<td> (459.0/4870.0)</td></tr>\n",
       "<tr><td>>50K</td>\n",
       "<td>356.0</td>\n",
       "<td>1159.0</td>\n",
       "<td>0.235</td>\n",
       "<td> (356.0/1515.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>4767.0</td>\n",
       "<td>1618.0</td>\n",
       "<td>0.1276</td>\n",
       "<td> (815.0/6385.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       <=50K    >50K    Error    Rate\n",
       "-----  -------  ------  -------  --------------\n",
       "<=50K  4411     459     0.0943   (459.0/4870.0)\n",
       ">50K   356      1159    0.235    (356.0/1515.0)\n",
       "Total  4767     1618    0.1276   (815.0/6385.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.3941338</td>\n",
       "<td>0.7398659</td>\n",
       "<td>196.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1609037</td>\n",
       "<td>0.8140209</td>\n",
       "<td>291.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.6428023</td>\n",
       "<td>0.7788191</td>\n",
       "<td>112.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4966910</td>\n",
       "<td>0.8815975</td>\n",
       "<td>159.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9985658</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0063333</td>\n",
       "<td>1.0</td>\n",
       "<td>389.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9985658</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.4816404</td>\n",
       "<td>0.6609098</td>\n",
       "<td>164.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.2859887</td>\n",
       "<td>0.8496920</td>\n",
       "<td>238.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.2756393</td>\n",
       "<td>0.8507648</td>\n",
       "<td>242.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.9985658</td>\n",
       "<td>4870.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.9985658</td>\n",
       "<td>1470.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0004319</td>\n",
       "<td>4870.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.0063333</td>\n",
       "<td>1515.0</td>\n",
       "<td>389.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.9985658</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.9985658</td>\n",
       "<td>0.9702970</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0004319</td>\n",
       "<td>1.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.0063333</td>\n",
       "<td>1.0</td>\n",
       "<td>389.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.394134     0.739866  196\n",
       "max f2                       0.160904     0.814021  291\n",
       "max f0point5                 0.642802     0.778819  112\n",
       "max accuracy                 0.496691     0.881597  159\n",
       "max precision                0.998566     1         0\n",
       "max recall                   0.00633325   1         389\n",
       "max specificity              0.998566     1         0\n",
       "max absolute_mcc             0.48164      0.66091   164\n",
       "max min_per_class_accuracy   0.285989     0.849692  238\n",
       "max mean_per_class_accuracy  0.275639     0.850765  242\n",
       "max tns                      0.998566     4870      0\n",
       "max fns                      0.998566     1470      0\n",
       "max fps                      0.000431912  4870      399\n",
       "max tps                      0.00633325   1515      389\n",
       "max tnr                      0.998566     1         0\n",
       "max fnr                      0.998566     0.970297  0\n",
       "max fpr                      0.000431912  1         399\n",
       "max tpr                      0.00633325   1         389"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate: 23.73 %, avg score: 24.06 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td>\n",
       "<td><b>kolmogorov_smirnov</b></td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.0100235</td>\n",
       "<td>0.9976195</td>\n",
       "<td>4.2145215</td>\n",
       "<td>4.2145215</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9983546</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9983546</td>\n",
       "<td>0.0422442</td>\n",
       "<td>0.0422442</td>\n",
       "<td>321.4521452</td>\n",
       "<td>321.4521452</td>\n",
       "<td>0.0422442</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0200470</td>\n",
       "<td>0.9954806</td>\n",
       "<td>4.2145215</td>\n",
       "<td>4.2145215</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9966830</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9975188</td>\n",
       "<td>0.0422442</td>\n",
       "<td>0.0844884</td>\n",
       "<td>321.4521452</td>\n",
       "<td>321.4521452</td>\n",
       "<td>0.0844884</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0300705</td>\n",
       "<td>0.9923587</td>\n",
       "<td>4.2145215</td>\n",
       "<td>4.2145215</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9942306</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9964227</td>\n",
       "<td>0.0422442</td>\n",
       "<td>0.1267327</td>\n",
       "<td>321.4521452</td>\n",
       "<td>321.4521452</td>\n",
       "<td>0.1267327</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0400940</td>\n",
       "<td>0.9851811</td>\n",
       "<td>4.2145215</td>\n",
       "<td>4.2145215</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9894556</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9946810</td>\n",
       "<td>0.0422442</td>\n",
       "<td>0.1689769</td>\n",
       "<td>321.4521452</td>\n",
       "<td>321.4521452</td>\n",
       "<td>0.1689769</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.0501175</td>\n",
       "<td>0.9644899</td>\n",
       "<td>4.1486696</td>\n",
       "<td>4.2013511</td>\n",
       "<td>0.984375</td>\n",
       "<td>0.9755751</td>\n",
       "<td>0.996875</td>\n",
       "<td>0.9908598</td>\n",
       "<td>0.0415842</td>\n",
       "<td>0.2105611</td>\n",
       "<td>314.8669554</td>\n",
       "<td>320.1351073</td>\n",
       "<td>0.2103557</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1000783</td>\n",
       "<td>0.7782860</td>\n",
       "<td>3.6992665</td>\n",
       "<td>3.9507016</td>\n",
       "<td>0.8777429</td>\n",
       "<td>0.8677746</td>\n",
       "<td>0.9374022</td>\n",
       "<td>0.9294135</td>\n",
       "<td>0.1848185</td>\n",
       "<td>0.3953795</td>\n",
       "<td>269.9266478</td>\n",
       "<td>295.0701643</td>\n",
       "<td>0.3871660</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.1500392</td>\n",
       "<td>0.6404153</td>\n",
       "<td>3.0651065</td>\n",
       "<td>3.6558114</td>\n",
       "<td>0.7272727</td>\n",
       "<td>0.7094499</td>\n",
       "<td>0.8674322</td>\n",
       "<td>0.8561689</td>\n",
       "<td>0.1531353</td>\n",
       "<td>0.5485149</td>\n",
       "<td>206.5106511</td>\n",
       "<td>265.5811406</td>\n",
       "<td>0.5224368</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2</td>\n",
       "<td>0.5050958</td>\n",
       "<td>2.4441582</td>\n",
       "<td>3.3531353</td>\n",
       "<td>0.5799373</td>\n",
       "<td>0.5741072</td>\n",
       "<td>0.7956147</td>\n",
       "<td>0.7857087</td>\n",
       "<td>0.1221122</td>\n",
       "<td>0.6706271</td>\n",
       "<td>144.4158209</td>\n",
       "<td>235.3135314</td>\n",
       "<td>0.6170336</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.3000783</td>\n",
       "<td>0.3120960</td>\n",
       "<td>1.6027053</td>\n",
       "<td>2.7693541</td>\n",
       "<td>0.3802817</td>\n",
       "<td>0.4044781</td>\n",
       "<td>0.6570981</td>\n",
       "<td>0.6585655</td>\n",
       "<td>0.1603960</td>\n",
       "<td>0.8310231</td>\n",
       "<td>60.2705341</td>\n",
       "<td>176.9354127</td>\n",
       "<td>0.6961155</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.4</td>\n",
       "<td>0.1621691</td>\n",
       "<td>0.9182108</td>\n",
       "<td>2.3069307</td>\n",
       "<td>0.2178683</td>\n",
       "<td>0.2331797</td>\n",
       "<td>0.5473767</td>\n",
       "<td>0.5523023</td>\n",
       "<td>0.0917492</td>\n",
       "<td>0.9227723</td>\n",
       "<td>-8.1789213</td>\n",
       "<td>130.6930693</td>\n",
       "<td>0.6854006</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5000783</td>\n",
       "<td>0.0735309</td>\n",
       "<td>0.4814712</td>\n",
       "<td>1.9416101</td>\n",
       "<td>0.1142410</td>\n",
       "<td>0.1134921</td>\n",
       "<td>0.4606953</td>\n",
       "<td>0.4644853</td>\n",
       "<td>0.0481848</td>\n",
       "<td>0.9709571</td>\n",
       "<td>-51.8528848</td>\n",
       "<td>94.1610102</td>\n",
       "<td>0.6173637</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.6</td>\n",
       "<td>0.0315599</td>\n",
       "<td>0.1783575</td>\n",
       "<td>1.6479648</td>\n",
       "<td>0.0423197</td>\n",
       "<td>0.0490362</td>\n",
       "<td>0.3910206</td>\n",
       "<td>0.3952980</td>\n",
       "<td>0.0178218</td>\n",
       "<td>0.9887789</td>\n",
       "<td>-82.1642509</td>\n",
       "<td>64.7964796</td>\n",
       "<td>0.5097234</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.6999217</td>\n",
       "<td>0.0134310</td>\n",
       "<td>0.0990875</td>\n",
       "<td>1.4268451</td>\n",
       "<td>0.0235110</td>\n",
       "<td>0.0212484</td>\n",
       "<td>0.3385545</td>\n",
       "<td>0.3418982</td>\n",
       "<td>0.0099010</td>\n",
       "<td>0.9986799</td>\n",
       "<td>-90.0912505</td>\n",
       "<td>42.6845146</td>\n",
       "<td>0.3916983</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.8</td>\n",
       "<td>0.0055148</td>\n",
       "<td>0.0131910</td>\n",
       "<td>1.25</td>\n",
       "<td>0.0031299</td>\n",
       "<td>0.0089043</td>\n",
       "<td>0.2965936</td>\n",
       "<td>0.3002414</td>\n",
       "<td>0.0013201</td>\n",
       "<td>1.0</td>\n",
       "<td>-98.6809010</td>\n",
       "<td>25.0</td>\n",
       "<td>0.2622177</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.8999217</td>\n",
       "<td>0.0015576</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1112078</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0032988</td>\n",
       "<td>0.2636617</td>\n",
       "<td>0.2672707</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.1207797</td>\n",
       "<td>0.1312115</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000845</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0008004</td>\n",
       "<td>0.2372749</td>\n",
       "<td>0.2406028</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  ---------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
       "1        0.0100235                   0.99762            4.21452    4.21452            1                0.998355     1                           0.998355            0.0422442       0.0422442                  321.452   321.452            0.0422442\n",
       "2        0.020047                    0.995481           4.21452    4.21452            1                0.996683     1                           0.997519            0.0422442       0.0844884                  321.452   321.452            0.0844884\n",
       "3        0.0300705                   0.992359           4.21452    4.21452            1                0.994231     1                           0.996423            0.0422442       0.126733                   321.452   321.452            0.126733\n",
       "4        0.040094                    0.985181           4.21452    4.21452            1                0.989456     1                           0.994681            0.0422442       0.168977                   321.452   321.452            0.168977\n",
       "5        0.0501175                   0.96449            4.14867    4.20135            0.984375         0.975575     0.996875                    0.99086             0.0415842       0.210561                   314.867   320.135            0.210356\n",
       "6        0.100078                    0.778286           3.69927    3.9507             0.877743         0.867775     0.937402                    0.929414            0.184818        0.39538                    269.927   295.07             0.387166\n",
       "7        0.150039                    0.640415           3.06511    3.65581            0.727273         0.70945      0.867432                    0.856169            0.153135        0.548515                   206.511   265.581            0.522437\n",
       "8        0.2                         0.505096           2.44416    3.35314            0.579937         0.574107     0.795615                    0.785709            0.122112        0.670627                   144.416   235.314            0.617034\n",
       "9        0.300078                    0.312096           1.60271    2.76935            0.380282         0.404478     0.657098                    0.658565            0.160396        0.831023                   60.2705   176.935            0.696116\n",
       "10       0.4                         0.162169           0.918211   2.30693            0.217868         0.23318      0.547377                    0.552302            0.0917492       0.922772                   -8.17892  130.693            0.685401\n",
       "11       0.500078                    0.0735309          0.481471   1.94161            0.114241         0.113492     0.460695                    0.464485            0.0481848       0.970957                   -51.8529  94.161             0.617364\n",
       "12       0.6                         0.0315599          0.178357   1.64796            0.0423197        0.0490362    0.391021                    0.395298            0.0178218       0.988779                   -82.1643  64.7965            0.509723\n",
       "13       0.699922                    0.013431           0.0990875  1.42685            0.023511         0.0212484    0.338554                    0.341898            0.00990099      0.99868                    -90.0913  42.6845            0.391698\n",
       "14       0.8                         0.00551483         0.013191   1.25               0.00312989       0.00890427   0.296594                    0.300241            0.00132013      1                          -98.6809  25                 0.262218\n",
       "15       0.899922                    0.00155759         0          1.11121            0                0.00329881   0.263662                    0.267271            0               1                          -100      11.1208            0.131211\n",
       "16       1                           8.44742e-05        0          1                  0                0.000800384  0.237275                    0.240603            0               1                          -100      0                  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model_performance(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "## Save the model for deployment\n",
    "\n",
    "Finally, for a model to be put into production, it needs to be saved in a manner that can be accessed later. H2O has several model formats, but the one most [preferred for production](https://docs.h2o.ai/h2o/latest-stable/h2o-docs/productionizing.html) is MOJO, or modified Java object. This allows the most general functionality and datatypes to be passed.\n",
    "\n",
    "The model is output as a .zip file that includes its single Java dependency, `h2o-genmodel.jar`. Java knowledge is therefore required to proceed to production deployment, but the format allows significant flexibility in where it can be deployed.\n",
    "\n",
    "The location that we save the model to is the Gradient-provided storage corresponding to this notebook, at `/storage`.\n",
    "\n",
    "In the command line section of this project (refer back to https://github.com/gradient-ai/Classical-ML-Example), we will deploy this model on Gradient as a REST endpoint, and send inference data to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "source_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to /storage/StackedEnsemble_AllModels_AutoML_20210713_220658.zip\n"
     ]
    }
   ],
   "source": [
    "modelfile = model.download_mojo(path=\"/storage\", get_genmodel_jar=True)\n",
    "print(\"Model saved to \" + modelfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "## Conclusions\n",
    "\n",
    "We have shown\n",
    "\n",
    " - Setup Java and H2O on Gradient\n",
    " - Load and prepare small dataset (UCI Census Income)\n",
    " - Train gradient-boosted decision tree and other models using H2O's AutoML\n",
    " - Evaluate model performance on unseen testing data\n",
    " - Save model so that it can be deployed to production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "## Next Steps\n",
    "To see the Workflow portion of this project, or to deploy the model using the command line, refer back to the project GitHub repo at https://github.com/gradient-ai/Classical-ML-Example ."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
